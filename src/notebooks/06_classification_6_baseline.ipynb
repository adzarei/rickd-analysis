{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8723be89",
   "metadata": {},
   "source": [
    "# First Classification attempt - Problem baseline\n",
    "\n",
    "I'm going to use machine learning models to predict the injury status of the players with the data we have.\n",
    "I do not expect to get good results, but I want to get a baseline to compare after improving the data and trying more advance techniques and models.\n",
    "\n",
    "I'm going to use the following models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Support Vector Machines\n",
    "\n",
    "## Approach: Using Scikit-learn Pipelines and Grid Search\n",
    "\n",
    "I'll implement a systematic approach using:\n",
    "1. **Pipelines**: To ensure consistent preprocessing across all models\n",
    "2. **Grid Search**: To find optimal hyperparameters for each model\n",
    "3. **Cross-validation**: To get reliable performance estimates\n",
    "4. **Model comparison**: To identify the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed56a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "import xgboost as xgb\n",
    "# import warnings\n",
    "\n",
    "import core.constants as c\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3668d",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818f2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Dataset shape: (1832, 93)\n",
      "X Columns: ['speed_r', 'age', 'Height', 'Weight', 'YrsRunning', 'NumRaces', 'l_step_width', 'l_stride_rate', 'l_stride_length', 'l_swing_time', 'l_stance_time', 'l_pelvis_peak_drop_angle', 'l_pelvis_drop_excursion', 'l_ankle_df_peak_angle', 'l_ankle_eve_peak_angle', 'l_ankle_eve_percent_stance', 'l_ankle_eve_excursion', 'l_ankle_rot_peak_angle', 'l_ankle_rot_excursion', 'l_knee_flex_peak_angle', 'l_knee_add_peak_angle', 'l_knee_add_excursion', 'l_knee_abd_peak_angle', 'l_knee_abd_excursion', 'l_knee_rot_peak_angle', 'l_knee_rot_excursion', 'l_hip_ext_peak_angle', 'l_hip_add_peak_angle', 'l_hip_add_excursion', 'l_hip_rot_peak_angle', 'l_hip_rot_excursion', 'l_foot_prog_angle', 'l_foot_ang_at_hs', 'l_mhw_exc_from_to', 'l_ankle_eve_peak_vel', 'l_ankle_rot_peak_vel', 'l_knee_abd_peak_vel', 'l_knee_add_peak_vel', 'l_hip_abd_peak_vel', 'l_knee_rot_peak_vel', 'l_hip_rot_peak_vel', 'l_pronation_onset', 'l_pronation_offset', 'l_peak_hip_add_velocity', 'l_peak_pelvic_drop_velocity', 'l_vertical_oscillation', 'r_step_width', 'r_stride_rate', 'r_stride_length', 'r_swing_time', 'r_stance_time', 'r_pelvis_peak_drop_angle', 'r_pelvis_drop_excursion', 'r_ankle_df_peak_angle', 'r_ankle_eve_peak_angle', 'r_ankle_eve_percent_stance', 'r_ankle_eve_excursion', 'r_ankle_rot_peak_angle', 'r_ankle_rot_excursion', 'r_knee_flex_peak_angle', 'r_knee_add_peak_angle', 'r_knee_add_excursion', 'r_knee_abd_peak_angle', 'r_knee_abd_excursion', 'r_knee_rot_peak_angle', 'r_knee_rot_excursion', 'r_hip_ext_peak_angle', 'r_hip_add_peak_angle', 'r_hip_add_excursion', 'r_hip_rot_peak_angle', 'r_hip_rot_excursion', 'r_foot_prog_angle', 'r_foot_ang_at_hs', 'r_mhw_exc_from_to', 'r_ankle_eve_peak_vel', 'r_ankle_rot_peak_vel', 'r_knee_abd_peak_vel', 'r_knee_add_peak_vel', 'r_hip_abd_peak_vel', 'r_knee_rot_peak_vel', 'r_hip_rot_peak_vel', 'r_pronation_onset', 'r_pronation_offset', 'r_peak_hip_add_velocity', 'r_peak_pelvic_drop_velocity', 'r_vertical_oscillation', 'Gender_female', 'Gender_male', 'DominantLeg_ambidextrous', 'DominantLeg_left', 'DominantLeg_right', 'Level_competitive', 'Level_recreational']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed_r</th>\n",
       "      <th>age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>YrsRunning</th>\n",
       "      <th>NumRaces</th>\n",
       "      <th>l_step_width</th>\n",
       "      <th>l_stride_rate</th>\n",
       "      <th>l_stride_length</th>\n",
       "      <th>l_swing_time</th>\n",
       "      <th>...</th>\n",
       "      <th>r_peak_hip_add_velocity</th>\n",
       "      <th>r_peak_pelvic_drop_velocity</th>\n",
       "      <th>r_vertical_oscillation</th>\n",
       "      <th>Gender_female</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>DominantLeg_ambidextrous</th>\n",
       "      <th>DominantLeg_left</th>\n",
       "      <th>DominantLeg_right</th>\n",
       "      <th>Level_competitive</th>\n",
       "      <th>Level_recreational</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100433_20101005t132240</th>\n",
       "      <td>-2.406926</td>\n",
       "      <td>1.231321</td>\n",
       "      <td>-11.741497</td>\n",
       "      <td>-5.056746</td>\n",
       "      <td>0.578686</td>\n",
       "      <td>-0.393107</td>\n",
       "      <td>-0.307243</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-2.622528</td>\n",
       "      <td>-0.338913</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743700</td>\n",
       "      <td>0.239058</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100434_20101117t132240</th>\n",
       "      <td>-1.095016</td>\n",
       "      <td>1.066816</td>\n",
       "      <td>-11.741497</td>\n",
       "      <td>-5.056746</td>\n",
       "      <td>1.308477</td>\n",
       "      <td>-0.393107</td>\n",
       "      <td>-1.831460</td>\n",
       "      <td>0.886585</td>\n",
       "      <td>-1.458975</td>\n",
       "      <td>-0.466027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764244</td>\n",
       "      <td>-0.390267</td>\n",
       "      <td>-1.344740</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100537_20120703t102550</th>\n",
       "      <td>-1.325076</td>\n",
       "      <td>-3.128072</td>\n",
       "      <td>0.097259</td>\n",
       "      <td>-0.179365</td>\n",
       "      <td>-0.568129</td>\n",
       "      <td>-0.393107</td>\n",
       "      <td>-0.037324</td>\n",
       "      <td>-0.643565</td>\n",
       "      <td>-1.241474</td>\n",
       "      <td>-0.084685</td>\n",
       "      <td>...</td>\n",
       "      <td>2.255015</td>\n",
       "      <td>0.604189</td>\n",
       "      <td>-0.284941</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100560_20120717t103748</th>\n",
       "      <td>-0.215279</td>\n",
       "      <td>-0.413733</td>\n",
       "      <td>0.521293</td>\n",
       "      <td>0.931754</td>\n",
       "      <td>-0.776641</td>\n",
       "      <td>-0.393107</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>-1.610390</td>\n",
       "      <td>0.439240</td>\n",
       "      <td>-1.165155</td>\n",
       "      <td>...</td>\n",
       "      <td>3.526927</td>\n",
       "      <td>-1.746297</td>\n",
       "      <td>1.346349</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101481_20120717t105021</th>\n",
       "      <td>-0.282875</td>\n",
       "      <td>-0.495986</td>\n",
       "      <td>0.316116</td>\n",
       "      <td>-0.828721</td>\n",
       "      <td>-0.776641</td>\n",
       "      <td>-0.393107</td>\n",
       "      <td>0.104643</td>\n",
       "      <td>-0.746010</td>\n",
       "      <td>-0.016982</td>\n",
       "      <td>-0.148242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475554</td>\n",
       "      <td>1.000454</td>\n",
       "      <td>0.657459</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         speed_r       age     Height    Weight  YrsRunning  \\\n",
       "id                                                                            \n",
       "100433_20101005t132240 -2.406926  1.231321 -11.741497 -5.056746    0.578686   \n",
       "100434_20101117t132240 -1.095016  1.066816 -11.741497 -5.056746    1.308477   \n",
       "100537_20120703t102550 -1.325076 -3.128072   0.097259 -0.179365   -0.568129   \n",
       "100560_20120717t103748 -0.215279 -0.413733   0.521293  0.931754   -0.776641   \n",
       "101481_20120717t105021 -0.282875 -0.495986   0.316116 -0.828721   -0.776641   \n",
       "\n",
       "                        NumRaces  l_step_width  l_stride_rate  \\\n",
       "id                                                              \n",
       "100433_20101005t132240 -0.393107     -0.307243       0.000986   \n",
       "100434_20101117t132240 -0.393107     -1.831460       0.886585   \n",
       "100537_20120703t102550 -0.393107     -0.037324      -0.643565   \n",
       "100560_20120717t103748 -0.393107      0.677045      -1.610390   \n",
       "101481_20120717t105021 -0.393107      0.104643      -0.746010   \n",
       "\n",
       "                        l_stride_length  l_swing_time  ...  \\\n",
       "id                                                     ...   \n",
       "100433_20101005t132240        -2.622528     -0.338913  ...   \n",
       "100434_20101117t132240        -1.458975     -0.466027  ...   \n",
       "100537_20120703t102550        -1.241474     -0.084685  ...   \n",
       "100560_20120717t103748         0.439240     -1.165155  ...   \n",
       "101481_20120717t105021        -0.016982     -0.148242  ...   \n",
       "\n",
       "                        r_peak_hip_add_velocity  r_peak_pelvic_drop_velocity  \\\n",
       "id                                                                             \n",
       "100433_20101005t132240                -1.743700                     0.239058   \n",
       "100434_20101117t132240                 0.764244                    -0.390267   \n",
       "100537_20120703t102550                 2.255015                     0.604189   \n",
       "100560_20120717t103748                 3.526927                    -1.746297   \n",
       "101481_20120717t105021                 0.475554                     1.000454   \n",
       "\n",
       "                        r_vertical_oscillation  Gender_female  Gender_male  \\\n",
       "id                                                                           \n",
       "100433_20101005t132240               -1.935588          False        False   \n",
       "100434_20101117t132240               -1.344740           True        False   \n",
       "100537_20120703t102550               -0.284941           True        False   \n",
       "100560_20120717t103748                1.346349           True        False   \n",
       "101481_20120717t105021                0.657459           True        False   \n",
       "\n",
       "                        DominantLeg_ambidextrous  DominantLeg_left  \\\n",
       "id                                                                   \n",
       "100433_20101005t132240                     False             False   \n",
       "100434_20101117t132240                     False             False   \n",
       "100537_20120703t102550                     False             False   \n",
       "100560_20120717t103748                     False             False   \n",
       "101481_20120717t105021                     False             False   \n",
       "\n",
       "                        DominantLeg_right  Level_competitive  \\\n",
       "id                                                             \n",
       "100433_20101005t132240              False              False   \n",
       "100434_20101117t132240              False              False   \n",
       "100537_20120703t102550               True              False   \n",
       "100560_20120717t103748               True              False   \n",
       "101481_20120717t105021              False              False   \n",
       "\n",
       "                        Level_recreational  \n",
       "id                                          \n",
       "100433_20101005t132240                True  \n",
       "100434_20101117t132240                True  \n",
       "100537_20120703t102550                True  \n",
       "100560_20120717t103748                True  \n",
       "101481_20120717t105021               False  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Dataset shape: (1832, 13)\n",
      "Y Columns: ['injury_severity_code', 'injury_severity_value', 'injury_code', 'injury2_code', 'injury_desc', 'injury2_desc', 'injury_name', 'injury2_name', 'injured_joint_code', 'injured_joint2_code', 'injured_side_code', 'injured_side2_code', 'is_injured']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_severity_code</th>\n",
       "      <th>injury_severity_value</th>\n",
       "      <th>injury_code</th>\n",
       "      <th>injury2_code</th>\n",
       "      <th>injury_desc</th>\n",
       "      <th>injury2_desc</th>\n",
       "      <th>injury_name</th>\n",
       "      <th>injury2_name</th>\n",
       "      <th>injured_joint_code</th>\n",
       "      <th>injured_joint2_code</th>\n",
       "      <th>injured_side_code</th>\n",
       "      <th>injured_side2_code</th>\n",
       "      <th>is_injured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100433_20101005t132240</th>\n",
       "      <td>volume_intensity</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pain</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>General sensation of discomfort  without speci...</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>pain</td>\n",
       "      <td>no injury</td>\n",
       "      <td>knee</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100434_20101117t132240</th>\n",
       "      <td>volume_intensity</td>\n",
       "      <td>2.0</td>\n",
       "      <td>disc_dege</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>Breakdown and gradual loss of spinal disc cush...</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>disc degeneration</td>\n",
       "      <td>no injury</td>\n",
       "      <td>lumbar_spine</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>bilateral</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100537_20120703t102550</th>\n",
       "      <td>missed_2_workouts</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pain</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>General sensation of discomfort  without speci...</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>pain</td>\n",
       "      <td>no injury</td>\n",
       "      <td>hip_pelvis</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100560_20120717t103748</th>\n",
       "      <td>no_injury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>no injury</td>\n",
       "      <td>no injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101481_20120717t105021</th>\n",
       "      <td>no_injury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>No injury has been diagnosed.</td>\n",
       "      <td>no injury</td>\n",
       "      <td>no injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>no_injury</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       injury_severity_code  injury_severity_value  \\\n",
       "id                                                                   \n",
       "100433_20101005t132240     volume_intensity                    2.0   \n",
       "100434_20101117t132240     volume_intensity                    2.0   \n",
       "100537_20120703t102550    missed_2_workouts                    3.0   \n",
       "100560_20120717t103748            no_injury                    0.0   \n",
       "101481_20120717t105021            no_injury                    0.0   \n",
       "\n",
       "                       injury_code injury2_code  \\\n",
       "id                                                \n",
       "100433_20101005t132240        pain    no_injury   \n",
       "100434_20101117t132240   disc_dege    no_injury   \n",
       "100537_20120703t102550        pain    no_injury   \n",
       "100560_20120717t103748   no_injury    no_injury   \n",
       "101481_20120717t105021   no_injury    no_injury   \n",
       "\n",
       "                                                              injury_desc  \\\n",
       "id                                                                          \n",
       "100433_20101005t132240  General sensation of discomfort  without speci...   \n",
       "100434_20101117t132240  Breakdown and gradual loss of spinal disc cush...   \n",
       "100537_20120703t102550  General sensation of discomfort  without speci...   \n",
       "100560_20120717t103748                      No injury has been diagnosed.   \n",
       "101481_20120717t105021                      No injury has been diagnosed.   \n",
       "\n",
       "                                         injury2_desc        injury_name  \\\n",
       "id                                                                         \n",
       "100433_20101005t132240  No injury has been diagnosed.               pain   \n",
       "100434_20101117t132240  No injury has been diagnosed.  disc degeneration   \n",
       "100537_20120703t102550  No injury has been diagnosed.               pain   \n",
       "100560_20120717t103748  No injury has been diagnosed.          no injury   \n",
       "101481_20120717t105021  No injury has been diagnosed.          no injury   \n",
       "\n",
       "                       injury2_name injured_joint_code injured_joint2_code  \\\n",
       "id                                                                           \n",
       "100433_20101005t132240    no injury               knee           no_injury   \n",
       "100434_20101117t132240    no injury       lumbar_spine           no_injury   \n",
       "100537_20120703t102550    no injury         hip_pelvis           no_injury   \n",
       "100560_20120717t103748    no injury          no_injury           no_injury   \n",
       "101481_20120717t105021    no injury          no_injury           no_injury   \n",
       "\n",
       "                       injured_side_code injured_side2_code  is_injured  \n",
       "id                                                                       \n",
       "100433_20101005t132240             right              right           1  \n",
       "100434_20101117t132240         bilateral              right           1  \n",
       "100537_20120703t102550             right              right           1  \n",
       "100560_20120717t103748             right              right           0  \n",
       "101481_20120717t105021         no_injury          no_injury           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = pd.read_csv(c.RICKD_BASELINE_X_FILE, index_col=0)\n",
    "Y = pd.read_csv(c.RICKD_BASELINE_Y_FILE, index_col=0)\n",
    "\n",
    "print(f\"X Dataset shape: {X.shape}\")\n",
    "print(f\"X Columns: {list(X.columns)}\")\n",
    "display(X.head())\n",
    "\n",
    "print(f\"Y Dataset shape: {Y.shape}\")\n",
    "print(f\"Y Columns: {list(Y.columns)}\")\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0456040a",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Target Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8ef042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1465 samples\n",
      "Test set: 367 samples\n",
      "Training target distribution: [532 933]\n",
      "Test target distribution: [133 234]\n"
     ]
    }
   ],
   "source": [
    "y = Y[\"is_injured\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training target distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test target distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0f57c",
   "metadata": {},
   "source": [
    "## 3. Define Model Pipelines with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75053f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    'Logistic Regression': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('classifier', LogisticRegression(random_state=RANDOM_STATE))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'classifier__C': [0.1, 1, 10, 100],\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Random Forest': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'XGBoost': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('classifier', xgb.XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss'))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [3, 6, 9],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'classifier__subsample': [0.8, 0.9, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'SVM': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('classifier', SVC(random_state=RANDOM_STATE, probability=True))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['rbf', 'linear'],\n",
    "            'classifier__gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb86ddf",
   "metadata": {},
   "source": [
    "## 4. Train Models with Grid Search and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d18b3a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Training Logistic Regression...\n",
      "\n",
      "======================\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best CV Score: 0.7574\n",
      "Best Parameters: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Test Accuracy: 0.7766\n",
      "Test Precision: 0.7793\n",
      "Test Recall: 0.7766\n",
      "Test F1-Score: 0.7632\n",
      "Test ROC AUC: 0.7818\n",
      "\n",
      "======================\n",
      "Training Random Forest...\n",
      "\n",
      "======================\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best CV Score: 0.7789\n",
      "Best Parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50}\n",
      "Test Accuracy: 0.7929\n",
      "Test Precision: 0.8221\n",
      "Test Recall: 0.7929\n",
      "Test F1-Score: 0.7715\n",
      "Test ROC AUC: 0.7643\n",
      "\n",
      "======================\n",
      "Training XGBoost...\n",
      "\n",
      "======================\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best CV Score: 0.8041\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 9, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "Test Accuracy: 0.8038\n",
      "Test Precision: 0.8170\n",
      "Test Recall: 0.8038\n",
      "Test F1-Score: 0.7898\n",
      "Test ROC AUC: 0.7780\n",
      "\n",
      "======================\n",
      "Training SVM...\n",
      "\n",
      "======================\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best CV Score: 0.7904\n",
      "Best Parameters: {'classifier__C': 10, 'classifier__gamma': 0.01, 'classifier__kernel': 'rbf'}\n",
      "Test Accuracy: 0.7847\n",
      "Test Precision: 0.7812\n",
      "Test Recall: 0.7847\n",
      "Test F1-Score: 0.7812\n",
      "Test ROC AUC: 0.8199\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "trained_models = {}\n",
    "results = {}\n",
    "\n",
    "for model_name, config in models_config.items():\n",
    "    print(f\"\\n{'======================'}\")\n",
    "    print(f\"Training {model_name}...\")\n",
    "    print(f\"\\n{'======================'}\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config['pipeline'],\n",
    "        param_grid=config['param_grid'],\n",
    "        cv=cv,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    trained_models[model_name] = grid_search\n",
    "    results[model_name] = {\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_results': grid_search.cv_results_\n",
    "    }\n",
    "    \n",
    "    print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    y_pred_proba = grid_search.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # For binary classification, calculate ROC AUC\n",
    "    if len(np.unique(y)) == 2:\n",
    "        test_roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "    else:\n",
    "        test_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    \n",
    "    results[model_name].update({\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'test_roc_auc': test_roc_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    })\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b99a8",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78434b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "for model_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'CV F1-Score': result['best_score'],\n",
    "        'Test Accuracy': result['test_accuracy'],\n",
    "        'Test Precision': result['test_precision'],\n",
    "        'Test Recall': result['test_recall'],\n",
    "        'Test F1-Score': result['test_f1'],\n",
    "        'Test ROC AUC': result['test_roc_auc']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test F1-Score', ascending=False)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Best F1-Score: {comparison_df.iloc[0]['Test F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: F1-Score comparison\n",
    "axes[0, 0].bar(comparison_df['Model'], comparison_df['Test F1-Score'], color='skyblue')\n",
    "axes[0, 0].set_title('Test F1-Score Comparison')\n",
    "axes[0, 0].set_ylabel('F1-Score')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "axes[0, 1].bar(comparison_df['Model'], comparison_df['Test Accuracy'], color='lightgreen')\n",
    "axes[0, 1].set_title('Test Accuracy Comparison')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Precision vs Recall\n",
    "axes[1, 0].scatter(comparison_df['Test Precision'], comparison_df['Test Recall'], \n",
    "                   s=100, alpha=0.7)\n",
    "for i, model in enumerate(comparison_df['Model']):\n",
    "    axes[1, 0].annotate(model, (comparison_df['Test Precision'].iloc[i], \n",
    "                               comparison_df['Test Recall'].iloc[i]),\n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "axes[1, 0].set_xlabel('Precision')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "axes[1, 0].set_title('Precision vs Recall')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: ROC AUC comparison\n",
    "axes[1, 1].bar(comparison_df['Model'], comparison_df['Test ROC AUC'], color='orange')\n",
    "axes[1, 1].set_title('Test ROC AUC Comparison')\n",
    "axes[1, 1].set_ylabel('ROC AUC')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc815c8",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the best model\n",
    "best_model = trained_models[best_model_name]\n",
    "best_results = results[best_model_name]\n",
    "\n",
    "print(f\"Detailed Analysis of {best_model_name}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_results['y_pred'], \n",
    "                          target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, best_results['y_pred'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (for tree-based models)\n",
    "if hasattr(best_model.best_estimator_.named_steps['classifier'], 'feature_importances_'):\n",
    "    feature_importance = best_model.best_estimator_.named_steps['classifier'].feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef6334",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a183b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cross-validation results for all models\n",
    "cv_results_df = pd.DataFrame()\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    cv_scores = result['cv_results']['mean_test_score']\n",
    "    cv_results_df[model_name] = cv_scores\n",
    "\n",
    "# Plot CV score distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "cv_results_df.boxplot()\n",
    "plt.title('Cross-Validation Score Distributions')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print CV statistics\n",
    "print(\"Cross-Validation Statistics:\")\n",
    "print(\"=\"*50)\n",
    "for model_name in cv_results_df.columns:\n",
    "    scores = cv_results_df[model_name]\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Mean CV Score: {scores.mean():.4f}\")\n",
    "    print(f\"  Std CV Score: {scores.std():.4f}\")\n",
    "    print(f\"  Min CV Score: {scores.min():.4f}\")\n",
    "    print(f\"  Max CV Score: {scores.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0400a1f",
   "metadata": {},
   "source": [
    "## 8. Model Persistence and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and results\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('../../results/models', exist_ok=True)\n",
    "\n",
    "# Save best model\n",
    "model_filename = f\"../../results/models/{best_model_name.lower().replace(' ', '_')}_best_model.pkl\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Best model saved to: {model_filename}\")\n",
    "\n",
    "# Save label encoder\n",
    "encoder_filename = f\"../../results/models/label_encoder.pkl\"\n",
    "joblib.dump(le, encoder_filename)\n",
    "print(f\"Label encoder saved to: {encoder_filename}\")\n",
    "\n",
    "# Save comparison results\n",
    "results_filename = f\"../../results/models/model_comparison_results.csv\"\n",
    "comparison_df.to_csv(results_filename, index=False)\n",
    "print(f\"Comparison results saved to: {results_filename}\")\n",
    "\n",
    "# Save detailed results as JSON\n",
    "detailed_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'best_model': best_model_name,\n",
    "    'best_model_params': results[best_model_name]['best_params'],\n",
    "    'model_comparison': comparison_df.to_dict('records'),\n",
    "    'data_info': {\n",
    "        'n_samples': len(data),\n",
    "        'n_features': X.shape[1],\n",
    "        'n_classes': len(le.classes_),\n",
    "        'class_distribution': dict(zip(le.classes_, np.bincount(y)))\n",
    "    }\n",
    "}\n",
    "\n",
    "json_filename = f\"../../results/models/experiment_results.json\"\n",
    "with open(json_filename, 'w') as f:\n",
    "    json.dump(detailed_results, f, indent=2)\n",
    "print(f\"Detailed results saved to: {json_filename}\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best Test F1-Score: {comparison_df.iloc[0]['Test F1-Score']:.4f}\")\n",
    "print(f\"Best Test Accuracy: {comparison_df.iloc[0]['Test Accuracy']:.4f}\")\n",
    "print(f\"Dataset: {len(data)} samples, {X.shape[1]} features\")\n",
    "print(f\"Classes: {len(le.classes_)} ({', '.join(le.classes_)})\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
